from confluent_kafka import Producer, Consumer, KafkaError, KafkaException
from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions
import json
import time
CONF = {
    'bootstrap.servers': '103.155.161.67:9093',
    'linger.ms': 10,  
    'socket.timeout.ms': 60000,   # Ch·ªù l√¢u h∆°n t√≠ cho ch·∫Øc
    'client.id': 'server_producer_app',
}
class KafkaManager:
    def __init__(self, conf):
        if conf is None:
            conf = CONF
        self.admin = AdminClient(conf)

    def create_topic(self, topic_name, num_patition=1, replication_factor=1):
        new_topic = NewTopic(topic_name, num_patition, replication_factor)
        fs = self.admin.create_topics(new_topics=[new_topic])

        for topic, f in fs.items():
            try:
                f.result()
                print("Create topic kafka successfully!")
            except KafkaException as e:
                error_obj = e.args[0]
                if error_obj.code() == KafkaError.TOPIC_ALREADY_EXISTS:
                    print(f"‚ö†Ô∏è Topic '{topic}' existed. Its ok!")
                else:
                    raise Exception(f"‚ùå Can not create '{topic}': {e}")
            except Exception as e:
                raise Exception(f"System Error!: {f}")


class KafkaProducer:
    def __init__(self, conf):
        if conf is None:
            conf = CONF
        self.producer = Producer(conf)

    def _ack(self, err, msg):
        if err is not None:
            print(f"Send Error: {err}")
        else:
            print(
                f"Send successfully: {msg.value().decode('utf-8')} (Topic: {msg.topic()})"
            )

    def send_json(self, topic, data):
        json_data = json.dumps(data).encode("utf-8")
        self.producer.produce(topic, json_data, callback=self._ack)
        self.producer.poll(0)

    def flush(self):
        self.producer.flush()


class KafkaConsumer:
    def __init__(self, topic, group_id="Uniform"):

        conf = CONF.copy()
        conf.update(
            {
                "group.id": group_id,
                "auto.offset.reset": "earliest",  # ƒê·ªçc t·ª´ ƒë·∫ßu n·∫øu l√† group m·ªõi
            }
        )
        self.consumer = Consumer(conf)
        self.consumer.subscribe([topic])

    def listen(self):
        print("üéß Waiting msg... ")
        try:
            while True:
                msg = self.consumer.poll(1.0)
                if msg is None:
                    continue
                if msg.error():
                    print(f"L·ªói Consumer: {msg.error()}")
                    continue

                raw_data = msg.value().decode("utf-8")
                data = json.loads(raw_data)
                print(f"üì• NH·∫¨N ƒê∆Ø·ª¢C: {data}")

        except KeyboardInterrupt:
            pass
        finally:
            self.consumer.close()


# --- DEMO C√ÅCH D√ôNG ---
# if __name__ == "__main__":
#     TOPIC = "camera_events"

#     # 1. Qu·∫£n tr·ªã: T·∫°o topic
#     manager = KafkaManager()
#     manager.create_topic(TOPIC)

#     # 2. Producer: B·∫Øn 5 tin gi·∫£ l·∫≠p
#     print("\n--- B·∫Øt ƒë·∫ßu g·ª≠i d·ªØ li·ªáu ---")
#     producer = KafkaProducer()
#     for i in range(5):
#         event = {"cam_id": 1, "frame_id": i, "status": "motion_detected"}
#         producer.send_json(TOPIC, event)
#         time.sleep(0.5)
#     producer.flush() # ƒê·∫£m b·∫£o tin ƒëi h·∫øt

#     # 3. Consumer: ƒê·ªçc l·∫°i tin v·ª´a b·∫Øn
#     print("\n--- B·∫Øt ƒë·∫ßu ƒë·ªçc d·ªØ li·ªáu ---")
#     consumer = KafkaConsumer(TOPIC)
#     consumer.listen()
